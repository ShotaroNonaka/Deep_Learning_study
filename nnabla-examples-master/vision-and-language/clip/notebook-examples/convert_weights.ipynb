{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convert_weights.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnUU7aOY8c-0",
        "outputId": "52672cfa-33eb-44fb-bce6-bba9191e2183"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-08_4fon5\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-08_4fon5\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.62.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.11.1+cu111)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)\n",
            "Building wheels for collected packages: clip, ftfy\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369221 sha256=cdb058abb5c8f5120d094afc92a36d8a8e48ca931f8ed21daf0e6c3db4c653e1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pijneu2t/wheels/fd/b9/c3/5b4470e35ed76e174bff77c92f91da82098d5e35fd5bc8cdac\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=e2a87eb6dcf62234b09e737b76ca62744723d21bd9aed2519cb77c9622624d56\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "Successfully built clip ftfy\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Libraries"
      ],
      "metadata": {
        "id": "yzjBhF-a9Lk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import nnabla as nn\n",
        "import nnabla.parametric_functions as PF\n",
        "\n",
        "import clip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_uUyAfH6AXC",
        "outputId": "44636f8a-830f-4745-c8eb-fc8261f406a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-02-01 15:59:33,868 [nnabla][INFO]: Initializing CPU extension...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select Model"
      ],
      "metadata": {
        "id": "4h8lp23R8x0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, _ = clip.load('ViT-B/32') # 'ViT-B/16', 'ViT-L/16'\n",
        "model = model.cpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSEOOwIW6nJz",
        "outputId": "f64718fb-4bff-4e6e-ab7d-77e65ee2a920"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 338M/338M [00:01<00:00, 194MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### output file name"
      ],
      "metadata": {
        "id": "3sWNSHgQ-D2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_file = './ViT-B-32.h5'"
      ],
      "metadata": {
        "id": "-8da6JC_-LcP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### utils"
      ],
      "metadata": {
        "id": "kuBGzwgw_jo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pytorch_to_nn_param_map():\n",
        "    '''map from tensor name to Nnabla default parameter names\n",
        "    '''\n",
        "    return {\n",
        "        'weight': 'W',\n",
        "        'bias': 'b',\n",
        "        '.': '/'\n",
        "    }\n",
        "\n",
        "def rename_params(param_name):\n",
        "    pytorch_to_nn_dict = pytorch_to_nn_param_map()\n",
        "    for k in pytorch_to_nn_dict:\n",
        "        if k in param_name:\n",
        "            param_name = param_name.replace(k, pytorch_to_nn_dict[k])\n",
        "    return param_name"
      ],
      "metadata": {
        "id": "9mtyzQIo-bIM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conversion"
      ],
      "metadata": {
        "id": "7sdlptOy_ubj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in model.named_parameters():\n",
        "  key = rename_params(k)\n",
        "  params = PF.get_parameter_or_create(key, shape=v.shape)\n",
        "  params.d = v.detach().numpy()"
      ],
      "metadata": {
        "id": "8VVCnJK9-iEv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save outputs"
      ],
      "metadata": {
        "id": "zDMSzPS3_m13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn.parameter.save_parameters(out_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-W8RQ5c-6xq",
        "outputId": "5ae4af1a-2220-4841-c242-9bdb39f07006"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-02-01 15:59:45,721 [nnabla][INFO]: Parameter save (.h5): ./ViT-B-32.h5\n"
          ]
        }
      ]
    }
  ]
}