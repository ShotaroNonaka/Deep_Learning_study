{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f6f71f-7100-4c19-b73e-56464752edd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 09:49:25,616 [nnabla][INFO]: Initializing CPU extension...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nnabla as nn\n",
    "import nnabla.functions as F\n",
    "import nnabla.parametric_functions as PF\n",
    "import nnabla.solvers as S\n",
    "from nnabla.ext_utils import get_extension_context\n",
    "from nnabla.utils.image_utils import imsave\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from gan.generate import synthesis\n",
    "from gan.networks import mapping_network, conv_block\n",
    "from gan.ops import upsample_2d, upsample_conv_2d, lerp, convert_images_to_uint8, weight_init_fn\n",
    "\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "709cdd1c-0d9f-4ae3-ba6c-4933fd17de13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 09:49:28,440 [nnabla][INFO]: Initializing CUDA extension...\n",
      "2021-09-15 09:49:28,455 [nnabla][INFO]: Initializing cuDNN extension...\n"
     ]
    }
   ],
   "source": [
    "# params\n",
    "SEED = 66\n",
    "batch_size = 1\n",
    "\n",
    "LR = 1e-2\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "EPOCHS = 200\n",
    "diff_epoch = 110\n",
    "\n",
    "truncation_psi = 0.5\n",
    "resolution = 1024\n",
    "\n",
    "imsave_freq = 5\n",
    "\n",
    "use_l2 = False\n",
    "l2_lambda = 0.008\n",
    "\n",
    "gan_path = './gan/face.h5'\n",
    "\n",
    "context = 'cudnn'\n",
    "ctx = get_extension_context(context)\n",
    "nn.set_default_context(ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "145154ac-73bb-48c6-b211-a314ca97fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.set_auto_forward(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8a25da-c885-4264-bdc5-70818ba09991",
   "metadata": {},
   "source": [
    "### input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9983efe9-2d37-45e9-93db-29bb7e0348f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"a man with blonde hair\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe6c428-d79e-4114-aacf-5b70af8d2ee8",
   "metadata": {},
   "source": [
    "### loss func for clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ded5ba06-e1cd-4a57-b810-c0dda944af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize(img, mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711), max_pixel_value=1.0):\n",
    "    mean = np.array(mean, dtype=np.float32)\n",
    "    mean = nn.Variable.from_numpy_array(mean)\n",
    "    mean *= max_pixel_value\n",
    "\n",
    "    std = np.array(std, dtype=np.float32)\n",
    "    std = nn.Variable.from_numpy_array(std)\n",
    "    std *= max_pixel_value\n",
    "\n",
    "    denominator = F.r_div_scalar(std)\n",
    "\n",
    "    mean = F.reshape(mean, (3, 1, 1))\n",
    "    denominator = F.reshape(denominator, (3, 1, 1))\n",
    "    \n",
    "    img -= mean\n",
    "    img *= denominator\n",
    "    return img\n",
    "\n",
    "def clip_loss(image, text):\n",
    "    with nn.parameter_scope('clip'):\n",
    "    \n",
    "        image = F.interpolate(image, output_size=(224, 224))\n",
    "        image = _normalize(image)\n",
    "\n",
    "        text = clip.tokenize(text)\n",
    "\n",
    "        img_logits, _ = clip.logits(image, text)\n",
    "        similarity = 1 - img_logits / 100\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c8c2686-0f78-4152-bfee-7aaaf0ff61fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nn.parameter_scope('clip'):\n",
    "    clip.load('data/ViT-B-32.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e7b77ed-6ddb-42de-b094-a897cc6cd66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e241e-1c80-408d-8459-f3d630e6c0ff",
   "metadata": {},
   "source": [
    "### learning params??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e4765b1-7ddf-4c5f-93d2-6b316a5d7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = np.random.RandomState(SEED)\n",
    "z = rnd.randn(batch_size, 512)\n",
    "\n",
    "style_noises = [nn.NdArray.from_numpy_array(z) for _ in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eb7ced4-abad-42b8-ad78-4976683941e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading styleGAN parmeters\n",
    "with nn.parameter_scope('gan'):\n",
    "    nn.load_parameters(gan_path)\n",
    "    \n",
    "    constant = nn.parameter.get_parameter_or_create(\n",
    "                name=\"G_synthesis/4x4/Const/const\",shape=(1, 512, 4, 4))\n",
    "    constant_bc = F.broadcast(constant, (batch_size,) + constant.shape[1:])\n",
    "    dlatent_avg = nn.parameter.get_parameter_or_create(\n",
    "                name=\"dlatent_avg\", shape=(1, 512))\n",
    "\n",
    "    style_noises_normalized = []\n",
    "    for style_noise in style_noises:\n",
    "        noise_std = (F.mean(style_noise ** 2., axis=1,\n",
    "                            keepdims=True)+1e-8) ** 0.5\n",
    "        style_noise_normalized = F.div2(style_noise, noise_std)\n",
    "        style_noises_normalized.append(style_noise_normalized)\n",
    "\n",
    "    w = [mapping_network(_, outmaps=512) for _ in style_noises_normalized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9999f162-3a18-435a-88fc-c2a4d28cbdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = [_ for _ in range(2)]\n",
    "latent_init = [_ for _ in range(2)]\n",
    "\n",
    "# create parameter to learn\n",
    "latent[0] =  nn.parameter.get_parameter_or_create(\n",
    "    name=\"latent/0\", shape=w[0].shape, initializer=w[0].data, need_grad=True)\n",
    "latent[1] =  nn.parameter.get_parameter_or_create(\n",
    "    name=\"latent/1\", shape=w[1].shape, initializer=w[1].data, need_grad=True)\n",
    "\n",
    "\n",
    "latent_init[0] = nn.Variable.from_numpy_array(latent[0].d.copy())\n",
    "latent_init[1] = nn.Variable.from_numpy_array(latent[1].d.copy())\n",
    "\n",
    "diff = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75bc1acf-65c7-4567-b659-3d167474d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = S.Adam(alpha=LR)\n",
    "with nn.parameter_scope('latent'):\n",
    "    solver.set_parameters(nn.get_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbabb2a-a7fa-4c3f-b098-7d1823c84c8f",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acfe1bcf-3cdd-47e1-934a-4225eae775c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0/200 - loss: 0.75592\n",
      "epoch: 10/200 - loss: 0.71544\n",
      "epoch: 20/200 - loss: 0.69196\n",
      "epoch: 30/200 - loss: 0.67529\n",
      "epoch: 40/200 - loss: 0.66550\n",
      "epoch: 50/200 - loss: 0.65958\n",
      "epoch: 60/200 - loss: 0.65478\n",
      "epoch: 70/200 - loss: 0.65097\n",
      "epoch: 80/200 - loss: 0.64785\n",
      "epoch: 90/200 - loss: 0.64506\n",
      "epoch: 100/200 - loss: 0.64204\n",
      "epoch: 110/200 - loss: 0.63864\n",
      "epoch: 120/200 - loss: 0.63538\n",
      "epoch: 130/200 - loss: 0.63249\n",
      "epoch: 140/200 - loss: 0.62984\n",
      "epoch: 150/200 - loss: 0.62685\n",
      "epoch: 160/200 - loss: 0.62370\n",
      "epoch: 170/200 - loss: 0.62071\n",
      "epoch: 180/200 - loss: 0.61771\n",
      "epoch: 190/200 - loss: 0.61514\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    # normalize noise inputs\n",
    "    with nn.parameter_scope('gan'):\n",
    "        # new latent space variable\n",
    "        w = [lerp(dlatent_avg, _, truncation_psi) for _ in latent]\n",
    "        rgb_output = synthesis(w, constant_bc, 1, 7, resolution=resolution)\n",
    "\n",
    "    \n",
    "    if epoch % imsave_freq == 0:\n",
    "        img = convert_images_to_uint8(rgb_output, drange=[-1, 1])\n",
    "        imsave(f'results/{epoch}.png', img[0], channel_first=True)\n",
    "    \n",
    "    \n",
    "    if use_l2:\n",
    "        l2_loss = F.sum((latent_init[0] - latent[0]) ** 2) + F.sum((latent_init[1] - latent[1]) ** 2)\n",
    "        l2_loss = l2_loss.reshape((1, 1))\n",
    "        loss = clip_loss(rgb_output[0], text) + l2_lambda * l2_loss\n",
    "    else:\n",
    "        loss = clip_loss(rgb_output[0], text)\n",
    "        \n",
    "    if epoch == diff_epoch:\n",
    "        diff.append((latent[0] - latent_init[0]).d.copy())\n",
    "        diff.append((latent[1] - latent_init[1]).d.copy())\n",
    "    \n",
    "    solver.zero_grad()\n",
    "    loss.backward(clear_buffer=True)\n",
    "    solver.update()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch: {}/{} - loss: {:.5f}'.format(epoch, EPOCHS, float(loss.d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc15389-deb4-4d5a-8ef8-0b39c5af11e8",
   "metadata": {},
   "source": [
    "### Image check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f558809c-b0ff-463d-8dbb-8c89c3e09331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "# encoder(for mp4)\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "# output file name, encoder, fps, size(fit to image size)\n",
    "video = cv2.VideoWriter('video.mp4',fourcc, 1, (1024, 1024))\n",
    "\n",
    "\n",
    "for i in range(0, EPOCHS, imsave_freq):\n",
    "    # hoge0000.png, hoge0001.png,..., hoge0090.png\n",
    "    img = cv2.imread(f'results/{i}.png')\n",
    "\n",
    "    # can't read image, escape\n",
    "    if img is None:\n",
    "        print(\"can't read\")\n",
    "        break\n",
    "\n",
    "    # add\n",
    "    video.write(img)\n",
    "    \n",
    "video.release()\n",
    "print('written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8367a780-3978-4753-9600-41cb6549546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [nn.Variable.from_numpy_array(n) for n in diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4197779-14ca-4ce0-b191-fef41e88dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = np.random.RandomState(67)\n",
    "z = rnd.randn(batch_size, 512)\n",
    "\n",
    "style_noises = [nn.NdArray.from_numpy_array(z) for _ in range(2)]\n",
    "\n",
    "# loading styleGAN parmeters\n",
    "with nn.parameter_scope('gan'):\n",
    "    nn.load_parameters(gan_path)\n",
    "    \n",
    "    constant = nn.parameter.get_parameter_or_create(\n",
    "                name=\"G_synthesis/4x4/Const/const\",shape=(1, 512, 4, 4))\n",
    "    constant_bc = F.broadcast(constant, (batch_size,) + constant.shape[1:])\n",
    "    dlatent_avg = nn.parameter.get_parameter_or_create(\n",
    "                name=\"dlatent_avg\", shape=(1, 512))\n",
    "\n",
    "    style_noises_normalized = []\n",
    "    for style_noise in style_noises:\n",
    "        noise_std = (F.mean(style_noise ** 2., axis=1,\n",
    "                            keepdims=True)+1e-8) ** 0.5\n",
    "        style_noise_normalized = F.div2(style_noise, noise_std)\n",
    "        style_noises_normalized.append(style_noise_normalized)\n",
    "\n",
    "    new_w = [mapping_network(_, outmaps=512) for _ in style_noises_normalized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8287fda3-e2d5-4c89-9b8b-75b96518ef51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<NdArray((1, 512)) at 0x2b931fbb96f0>, <NdArray((1, 512)) at 0x2b931fbb9690>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aba1505-6991-433b-9c22-3ca425e9ec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_latent = []\n",
    "new_latent.append(new_w[0] - q[0])\n",
    "new_latent.append(new_w[1] - q[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "689906bd-fbd3-491c-ada0-c5f67fdd3dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<NdArray((1, 512)) at 0x2b931fbb97b0>, <NdArray((1, 512)) at 0x2b931fbb98a0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "891df407-15f1-4590-bf3d-d436d6432bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nn.parameter_scope('gan'):\n",
    "    # new latent space variable\n",
    "    w = [lerp(dlatent_avg, _, truncation_psi) for _ in new_latent]\n",
    "    new_rgb_output = synthesis(w, constant_bc, 1, 7, resolution=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e75ed825-1cd8-439f-bd6f-aa65cab65774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NdArray((1, 3, 1024, 1024)) at 0x2b931fbb9d80>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rgb_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92599c14-c382-4fee-8ac7-c5a3d9547838",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = convert_images_to_uint8(new_rgb_output, drange=[-1, 1])\n",
    "imsave('res_6.png', img[0], channel_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7569cba-9713-484d-ba9f-53446150a4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
