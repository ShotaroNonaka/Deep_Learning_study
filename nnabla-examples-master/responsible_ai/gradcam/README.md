# Grad-CAM
**Grad**ient-weighted **C**lass **A**ctivation **M**apping, **Grad-CAM**, is a technique for making visual explanations for decisions from CNN-based models. Grad-CAM utilizes gradients of any target concept into the final convolution layer, which highlights important region of the decisions. This is an implementation of Neural Network Libraries on [Grad-CAM](https://openaccess.thecvf.com/content_iccv_2017/html/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.html). 


<p align="center">
<img src='images/sample.png'>
</p>
<p align="center">
Figure: Visual explanations on the image samples.
</p>


# Interactive demo

**eXplainable AI**
|Name| Notebook           | Task  | Example                       |
|:---------------------------------:|:-------------:|:-----:|:------------:|
 [Grad-CAM](https://openaccess.thecvf.com/content_iccv_2017/html/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.html) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sony/nnabla-examples/blob/master/interactive-demos/gradcam.ipynb) | Grad-CAM |<a href="url"><img src="https://github.com/sony/nnabla-examples/raw/master/responsible_ai/gradcam/images/sample.png" align="center" height="90" ></a>|
 
# Citation
This is based on [Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization](https://openaccess.thecvf.com/content_iccv_2017/html/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.html).

